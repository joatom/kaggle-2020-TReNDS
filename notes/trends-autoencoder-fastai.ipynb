{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Just getting started ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import h5py\n",
    "\n",
    "#import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "\n",
    "from fastai.vision import * \n",
    "from fastai import *\n",
    "\n",
    "import os, shutil\n",
    "import sys\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "kaggle_path = Path('.') # '.'\n",
    "kaggle_input_path = Path('/kaggle/input/trends-assessment-prediction') # '/kaggle/input/trends-assessment-prediction'\n",
    "mri_train_path = Path('/kaggle/input/trends-assessment-prediction/fMRI_train') #fMRI_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTATION_STRAT = 'IGNORE_ON_TRAIN' # 'IGNORE_ON_TRAIN', 'MEAN' \n",
    "LOSS_BASE = 'MSE' # 'MSE' # 'L1' 'MIX' 'VAR'\n",
    "LOSS_WEIGHTS = [0.3, 0.175, 0.175, 0.175, 0.175] #[0.2,0.2,0.2,0.2,0.2] #[0,0,0,0,1]#\n",
    "\n",
    "DEP_VAR = ['age','domain1_var1','domain1_var2', 'domain2_var1', 'domain2_var2']\n",
    "\n",
    "bs=4"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "TODO:add test to y_data and change dataloader, so it picks img from test and train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(kaggle_input_path/'train_scores.csv')\n",
    "y_data = y_data.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 53, 52, 63, 53)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= h5py.File(mri_train_path/'10001.mat','r')\n",
    "data=f['SM_feature'][()]\n",
    "data.reshape(1,53,52,63,53).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIImageList2(ImageList):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    \n",
    "    def get(self, i):\n",
    "        fname = self.items[i]\n",
    "        \n",
    "        f= h5py.File(fname,'r')\n",
    "        data=f['SM_feature'][()]\n",
    "        \n",
    "        return torch.tensor(data).permute(3,1,0,2).float()\n",
    "\n",
    "\n",
    "class MRIImageList2_Target(ImageList):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    \n",
    "    def get(self, i):\n",
    "        \n",
    "        y_features = torch.tensor(y_data.iloc[i].values[1:]).float()\n",
    "        \n",
    "        fname = self.items[i]\n",
    "        \n",
    "        f= h5py.File(fname,'r')\n",
    "        imgdata=f['SM_feature'][()]\n",
    "        imgdata=torch.tensor(imgdata).permute(3,1,0,2).float().flatten()\n",
    "        \n",
    "        return torch.cat((imgdata, y_features) ,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://github.com/fastai/fastai/blob/master/fastai/vision/data.py#L414\n",
    "class MRIImageImageList2(MRIImageList2):\n",
    "    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n",
    "    _label_cls, _square_show, _square_show_res = MRIImageList2_Target, False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data():\n",
    "    return (MRIImageImageList2.from_df(df = y_data, path=kaggle_input_path, cols=['Id'], folder='fMRI_train', suffix='.mat')\n",
    "          #  .split_none()\n",
    "        #.split_by_idx(valid_idx=range(200,400))\n",
    "        .split_by_rand_pct(0.1)    \n",
    "        #.split_by_files(valid_names = [f'valid_{task}_{i}.png' for i in range(task_info[task]['num_test'])])\n",
    "        #.label_from_df(cols=DEP_VAR)\n",
    "        .label_from_func(lambda x: x) #range(10)\n",
    "        #.transform(get_transforms(), tfm_y=True, size=256, padding_mode = 'border')  #256 #xtra_tfms=[cutout(n_holes=(1,8), length=(16, 16), p=.7)]\n",
    "        .databunch(bs=bs) #64)\n",
    "        #.normalize(imagenet_stats)\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Loss function combines autoencoder image generating loss and feature loss, if features are the 5 target variables (0 values are ignored, so test data could be included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixed_Loss(nn.Module):\n",
    "    def __init__(self, loss_weights = [0.4,0.15,0.15,0.15,0.15], loss_base = 'MSE', bs=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bs=bs\n",
    "        \n",
    "        self.loss_base = loss_base\n",
    "        \n",
    "        self.loss_weights = loss_weights\n",
    "        self.fw = Tensor(LOSS_WEIGHTS).cuda()\n",
    "        self.student_weight = 0.01 # 0.01 #.1\n",
    "          \n",
    "            \n",
    "    def forward(self, input, target,reduction='sum'): #mean\n",
    "        autoencoder_loss = F.mse_loss(input[:,:-5], target[:,:-5], reduction='mean') * bs #view(self.bs,-1))\n",
    "        \n",
    "        #return autoencoder_loss\n",
    "        \n",
    "        features = input[:,-5:].T\n",
    "        target_feat = target[:,-5:]\n",
    "        \n",
    "        x0,x1,x2,x3,x4 = features\n",
    "        \n",
    "        ## use sign for 0 imputeted empty targets, so they wan't be evaluated\n",
    "        if IMPUTATION_STRAT == 'IGNORE_ON_TRAIN':\n",
    "            sg = target_feat.float().sign()\n",
    "            x0,x1,x2,x3,x4 = x0.float()*sg[:,0],x1.float()*sg[:,1],x2.float()*sg[:,2],x3.float()*sg[:,3],x4.float()*sg[:,4]\n",
    "        else: # 'MEAN'\n",
    "            sg = 1\n",
    "            x0,x1,x2,x3,x4 = x0.float(),x1.float(),x2.float(),x3.float(),x4.float()\n",
    "            \n",
    "        y = target_feat.float()*sg\n",
    "        \n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        if self.loss_base in ('MSE','MIX'):\n",
    "            loss_func = F.mse_loss \n",
    "            #reduction = 'sum'\n",
    "            #loss1 = self.fw[0]*loss_func(x0,y[:,0],reduction=reduction)/sum(y[:,0]**2) + \\\n",
    "            #   self.fw[1]*loss_func(x1,y[:,1],reduction=reduction)/sum(y[:,1]**2) + \\\n",
    "            #   self.fw[2]*loss_func(x2,y[:,2],reduction=reduction)/sum(y[:,2]**2) + \\\n",
    "            #   self.fw[3]*loss_func(x3,y[:,3],reduction=reduction)/sum(y[:,3]**2) + \\\n",
    "            #   self.fw[4]*loss_func(x4,y[:,4],reduction=reduction)/sum(y[:,4]**2)\n",
    "            \n",
    "            loss1 = (self.fw*(F.mse_loss(features.T*sg,y,reduction='none').sum(dim=0))/((y**2.5).sum(dim=0)))*3\n",
    "            loss1 = loss1.sum()*self.bs\n",
    "        \n",
    "        if self.loss_base in ('L1','MIX'):\n",
    "            loss_func = F.l1_loss \n",
    "            #reduction = 'mean'\n",
    "            #loss2 =  self.fw[0]*loss_func(x0,y[:,0],reduction=reduction) + \\\n",
    "            #   self.fw[1]*loss_func(x1,y[:,1],reduction=reduction) + \\\n",
    "            #   self.fw[2]*loss_func(x2,y[:,2],reduction=reduction) + \\\n",
    "            #   self.fw[3]*loss_func(x3,y[:,3],reduction=reduction) + \\\n",
    "            #   self.fw[4]*loss_func(x4,y[:,4],reduction=reduction)\n",
    "            \n",
    "            reduction = 'sum'\n",
    "            loss2 =  self.fw[0]*loss_func(x0,y[:,0],reduction=reduction)/sum(y[:,0]) + \\\n",
    "               self.fw[1]*loss_func(x1,y[:,1],reduction=reduction)/sum(y[:,1]) + \\\n",
    "               self.fw[2]*loss_func(x2,y[:,2],reduction=reduction)/sum(y[:,2]) + \\\n",
    "               self.fw[3]*loss_func(x3,y[:,3],reduction=reduction)/sum(y[:,3]) + \\\n",
    "               self.fw[4]*loss_func(x4,y[:,4],reduction=reduction)/sum(y[:,4])\n",
    "            loss2 = loss2*self.bs/4\n",
    "\n",
    "        return autoencoder_loss/10 + loss1 + loss2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nf):\n",
    "        super(AutoEncoderBlock, self).__init__()\n",
    "        \n",
    "        track_running_stats = True\n",
    "        affine=True\n",
    "        \n",
    "        self.encoder3d = nn.Sequential(\n",
    "            # since gradients are accum over several batches dont use batchnorm, see\n",
    "            # https://docs.fast.ai/train.html#AccumulateScheduler\n",
    "            nn.InstanceNorm3d(53, track_running_stats=track_running_stats, affine=affine),\n",
    "            nn.Conv3d(nf, 10, 7, stride=(1,2,2), padding =3),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Dropout3d(0.1),\n",
    "            #Lambda(lambda x: x.sin()),\n",
    "            nn.InstanceNorm3d(10, track_running_stats=track_running_stats, affine=affine),\n",
    "            nn.Conv3d(10, 1, 5, stride=1, padding = 2),\n",
    "            \n",
    "            #Lambda(lambda x: x.sin())\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout3d(0.1)\n",
    "        )\n",
    "        \n",
    "        self.encoder2d = nn.Sequential(\n",
    "            nn.InstanceNorm2d(52, track_running_stats=track_running_stats, affine=affine),\n",
    "            nn.Conv2d(52, 3, 1, stride=1, padding =0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout2d(0.1)\n",
    "            #Lambda(lambda x: x.sin()),\n",
    "        )\n",
    "        \n",
    "        self.decoder2d = nn.Sequential(\n",
    "            \n",
    "            nn.InstanceNorm2d(3, track_running_stats=track_running_stats, affine=affine),\n",
    "            nn.ConvTranspose2d(3, 52, 1, stride=1, padding = 0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        \n",
    "        self.decoder3d = nn.Sequential(\n",
    "            \n",
    "            nn.InstanceNorm3d(1, track_running_stats=track_running_stats, affine=affine),\n",
    "            nn.ConvTranspose3d(1, 10, 5, stride=1, padding = 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout3d(0.1),\n",
    "            \n",
    "            nn.InstanceNorm3d(10, track_running_stats=track_running_stats, affine=affine),\n",
    "            nn.ConvTranspose3d(10, nf, 7, stride=(1,2,2), padding = 3),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Hardshrink()\n",
    "        )\n",
    "    \n",
    "    \n",
    "        self.feature_generator = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            #nn.InstanceNorm1d(2592, track_running_stats=track_running_stats),\n",
    "            nn.Linear(2592,8),\n",
    "            nn.Dropout(0.1),\n",
    "            #nn.InstanceNorm1d(8, track_running_stats=track_running_stats),\n",
    "            nn.Linear(8,5),\n",
    "            SigmoidRange(Tensor([12,12,0,0,0]).cuda(),Tensor([90,90,100,100,100]).cuda())\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input #self.c3d_to_2d(input) #[:,:,:,:,10]\n",
    "       # print(x.shape)\n",
    "        x = self.encoder3d(x)\n",
    "       # print(x.shape)\n",
    "        x = x.view(-1,52, 27, 32)\n",
    "        x = self.encoder2d(x)\n",
    "       # print(x.shape)\n",
    "    \n",
    "        features = self.feature_generator(x)\n",
    "        \n",
    "        x = self.decoder2d(x)\n",
    "       # print(x.shape)\n",
    "        x = x.view(-1,1,52, 27, 32)\n",
    "       # print(x.shape)\n",
    "        x = self.decoder3d(x)\n",
    "       # print(x.shape)\n",
    "        \n",
    "        return torch.cat((x,features),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "learner accumulates gradients over n_steps because batch size is small. Backprop happens after bs*n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data(), AutoEncoderBlock(53), \n",
    "                    loss_func = Mixed_Loss(loss_weights = LOSS_WEIGHTS,  \n",
    "                                             loss_base= LOSS_BASE, bs=bs),\n",
    "               # loss_func=F.mse_loss,\n",
    "                        metrics=[mean_absolute_error,mean_squared_error],\n",
    "                callback_fns=partial(AccumulateScheduler, n_step=16))\n",
    "\n",
    "learn.clip_grad = 1.0\n",
    "\n",
    "learn.model_dir = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='80' class='' max='1322' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.05% [80/1322 04:01<1:02:30 0.4395]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.223255</td>\n",
       "      <td>0.219145</td>\n",
       "      <td>0.227157</td>\n",
       "      <td>0.310198</td>\n",
       "      <td>1:13:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.215359</td>\n",
       "      <td>0.211605</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.292173</td>\n",
       "      <td>1:14:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206063</td>\n",
       "      <td>0.210447</td>\n",
       "      <td>0.221537</td>\n",
       "      <td>0.289964</td>\n",
       "      <td>1:13:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3,2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/kaggle/input/trends-assessment-prediction/export.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8dfc9170dc83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, file, destroy)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mxtra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mtry_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdestroy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mtry_save\u001b[0;34m(state, path, file)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtry_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPathLikeOrBinaryStream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_pathlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/trends-assessment-prediction/export.pkl'"
     ]
    }
   ],
   "source": [
    "learn.model_dir = '/kaggle/working'\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
