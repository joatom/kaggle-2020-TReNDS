{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# TReNDS - Exploring tabular augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Augmentation is broadly used for sample generation and regularization in image classification. This is an experiment to use the techniques on tabular data. I'm starting here with mixup and may add more in the future, if I feel motivated.\n",
    "\n",
    "## Credits\n",
    "Many ideas of my notebook are derived from this [notebook](https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964#MixUp) from the Bengaliai competition earlier this year. Please go there and upvote if you find this or other references usefull.\n",
    "Here are the references in detail:\n",
    "- https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964#MixUp: Multi head - metrics, - loss function, - mixup.\n",
    "- https://github.com/fastai/fastai/tree/master/fastai: mixup and many more\n",
    "- https://forums.fast.ai/t/tabulardata-mixup/52011/6: tabular mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.tabular import * \n",
    "from fastai import *\n",
    "\n",
    "import os, shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Notebook Settings\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "kaggle_path = Path('.')\n",
    "kaggle_input_path = Path('/kaggle/input/trends-assessment-prediction')\n",
    "\n",
    "#for dirname, _, filenames in os.walk(kaggle_input_path):\n",
    "#    print(dirname, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_FNC_DATA = False\n",
    "IMPUTATION_STRAT = 'IGNORE_ON_TRAIN' # 'IGNORE_ON_TRAIN', 'MEAN' \n",
    "LOSS_BASE = 'MSE' # 'L1'\n",
    "LOSS_WEIGHTS = [0.4, 0.15, 0.15, 0.15, 0.15]\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "l_data = pd.read_csv(kaggle_input_path/'loading.csv')\n",
    "\n",
    "if INCLUDE_FNC_DATA:\n",
    "    f_data = pd.read_csv(kaggle_input_path/'fnc.csv')\n",
    "    l_data = l_data.merge(f_data, on='Id', how = 'inner')\n",
    "\n",
    "y_data = pd.read_csv(kaggle_input_path/'train_scores.csv')\n",
    "\n",
    "idx_site2 = pd.read_csv(kaggle_input_path/'reveal_ID_site2.csv')\n",
    "#submission = pd.read_csv(kaggle_input_path/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0  10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1  10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2  10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3  10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4  10007  38.617381     49.197021     65.674285     40.151376     34.096421"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5877.000000</td>\n",
       "      <td>5877.000000</td>\n",
       "      <td>5439.000000</td>\n",
       "      <td>5439.000000</td>\n",
       "      <td>5838.000000</td>\n",
       "      <td>5838.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15909.667007</td>\n",
       "      <td>50.034068</td>\n",
       "      <td>51.474692</td>\n",
       "      <td>59.244132</td>\n",
       "      <td>47.325130</td>\n",
       "      <td>51.905658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3411.775315</td>\n",
       "      <td>13.539881</td>\n",
       "      <td>10.188354</td>\n",
       "      <td>11.387595</td>\n",
       "      <td>11.124863</td>\n",
       "      <td>11.839203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>15.769168</td>\n",
       "      <td>1.021874</td>\n",
       "      <td>0.991172</td>\n",
       "      <td>0.815285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12961.000000</td>\n",
       "      <td>40.129361</td>\n",
       "      <td>44.781240</td>\n",
       "      <td>52.396805</td>\n",
       "      <td>40.122682</td>\n",
       "      <td>44.514880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15925.000000</td>\n",
       "      <td>50.427747</td>\n",
       "      <td>51.847306</td>\n",
       "      <td>60.052535</td>\n",
       "      <td>47.811205</td>\n",
       "      <td>52.572032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18886.000000</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>58.495576</td>\n",
       "      <td>67.142611</td>\n",
       "      <td>55.058014</td>\n",
       "      <td>59.910146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21754.000000</td>\n",
       "      <td>84.491113</td>\n",
       "      <td>81.325580</td>\n",
       "      <td>94.702874</td>\n",
       "      <td>82.164478</td>\n",
       "      <td>94.509903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id          age  domain1_var1  domain1_var2  domain2_var1  \\\n",
       "count   5877.000000  5877.000000   5439.000000   5439.000000   5838.000000   \n",
       "mean   15909.667007    50.034068     51.474692     59.244132     47.325130   \n",
       "std     3411.775315    13.539881     10.188354     11.387595     11.124863   \n",
       "min    10001.000000    14.257265     15.769168      1.021874      0.991172   \n",
       "25%    12961.000000    40.129361     44.781240     52.396805     40.122682   \n",
       "50%    15925.000000    50.427747     51.847306     60.052535     47.811205   \n",
       "75%    18886.000000    59.580851     58.495576     67.142611     55.058014   \n",
       "max    21754.000000    84.491113     81.325580     94.702874     82.164478   \n",
       "\n",
       "       domain2_var2  \n",
       "count   5838.000000  \n",
       "mean      51.905658  \n",
       "std       11.839203  \n",
       "min        0.815285  \n",
       "25%       44.514880  \n",
       "50%       52.572032  \n",
       "75%       59.910146  \n",
       "max       94.509903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5877, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y_data.head())\n",
    "display(y_data.describe())\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>IC_01</th>\n",
       "      <th>IC_07</th>\n",
       "      <th>IC_05</th>\n",
       "      <th>IC_16</th>\n",
       "      <th>IC_26</th>\n",
       "      <th>IC_06</th>\n",
       "      <th>IC_10</th>\n",
       "      <th>IC_09</th>\n",
       "      <th>IC_18</th>\n",
       "      <th>...</th>\n",
       "      <th>IC_08</th>\n",
       "      <th>IC_03</th>\n",
       "      <th>IC_21</th>\n",
       "      <th>IC_28</th>\n",
       "      <th>IC_11</th>\n",
       "      <th>IC_20</th>\n",
       "      <th>IC_30</th>\n",
       "      <th>IC_22</th>\n",
       "      <th>IC_29</th>\n",
       "      <th>IC_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11749</th>\n",
       "      <td>21750</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.022840</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.029689</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.017492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11750</th>\n",
       "      <td>21751</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>-0.008028</td>\n",
       "      <td>0.035093</td>\n",
       "      <td>0.017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>21752</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.020741</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.007140</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>0.021665</td>\n",
       "      <td>0.019592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>21753</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>-0.005623</td>\n",
       "      <td>-0.006399</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>-0.008130</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>0.029326</td>\n",
       "      <td>0.014235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11753</th>\n",
       "      <td>21754</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.001773</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>-0.007732</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>-0.020373</td>\n",
       "      <td>0.023804</td>\n",
       "      <td>0.012477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id     IC_01     IC_07     IC_05     IC_16     IC_26     IC_06  \\\n",
       "11749  21750  0.005996  0.003873  0.012353  0.000242 -0.002159  0.020201   \n",
       "11750  21751  0.003835  0.015067  0.015428 -0.002030  0.001205  0.012396   \n",
       "11751  21752  0.000627  0.011407  0.010957  0.000534 -0.000347  0.013499   \n",
       "11752  21753  0.007431  0.021419  0.014143 -0.005623 -0.006399  0.008602   \n",
       "11753  21754  0.010670  0.010670  0.006662 -0.002215 -0.001773  0.006544   \n",
       "\n",
       "          IC_10     IC_09     IC_18  ...     IC_08     IC_03     IC_21  \\\n",
       "11749  0.020931  0.003684 -0.002458  ...  0.011454  0.022840  0.006448   \n",
       "11750  0.011026 -0.001491  0.005310  ...  0.012303  0.018314  0.012326   \n",
       "11751  0.010541  0.001867  0.007447  ...  0.012055  0.020741  0.001160   \n",
       "11752  0.006831 -0.001018  0.014972  ...  0.019220  0.026282  0.020715   \n",
       "11753  0.010900  0.000563  0.002995  ...  0.012511  0.023367  0.010739   \n",
       "\n",
       "          IC_28     IC_11     IC_20     IC_30     IC_22     IC_29     IC_14  \n",
       "11749 -0.007203  0.029689  0.004942  0.007751 -0.020226  0.028821  0.017492  \n",
       "11750 -0.012152  0.024617  0.002096  0.001911 -0.008028  0.035093  0.017439  \n",
       "11751 -0.007140  0.025236  0.002026  0.001876 -0.014612  0.021665  0.019592  \n",
       "11752 -0.008130  0.025149  0.007695  0.003226 -0.003505  0.029326  0.014235  \n",
       "11753 -0.007732  0.015962  0.002420  0.003115 -0.020373  0.023804  0.012477  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>IC_01</th>\n",
       "      <th>IC_07</th>\n",
       "      <th>IC_05</th>\n",
       "      <th>IC_16</th>\n",
       "      <th>IC_26</th>\n",
       "      <th>IC_06</th>\n",
       "      <th>IC_10</th>\n",
       "      <th>IC_09</th>\n",
       "      <th>IC_18</th>\n",
       "      <th>...</th>\n",
       "      <th>IC_08</th>\n",
       "      <th>IC_03</th>\n",
       "      <th>IC_21</th>\n",
       "      <th>IC_28</th>\n",
       "      <th>IC_11</th>\n",
       "      <th>IC_20</th>\n",
       "      <th>IC_30</th>\n",
       "      <th>IC_22</th>\n",
       "      <th>IC_29</th>\n",
       "      <th>IC_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "      <td>11754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15877.500000</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>-0.008081</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>-0.014729</td>\n",
       "      <td>0.026623</td>\n",
       "      <td>0.016187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3393.231867</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.003731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>-0.015894</td>\n",
       "      <td>-0.015927</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.015118</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>-0.009622</td>\n",
       "      <td>-0.027575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005282</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>-0.010426</td>\n",
       "      <td>-0.020051</td>\n",
       "      <td>0.008485</td>\n",
       "      <td>-0.007969</td>\n",
       "      <td>-0.007720</td>\n",
       "      <td>-0.040384</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12939.250000</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>-0.001319</td>\n",
       "      <td>-0.002904</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>-0.010231</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>-0.018738</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>0.013595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15877.500000</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>-0.008101</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>-0.014498</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>0.016031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18815.750000</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.016186</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>-0.005915</td>\n",
       "      <td>0.026302</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>-0.010635</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>0.018599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21754.000000</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>0.026218</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>0.035586</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028522</td>\n",
       "      <td>0.036454</td>\n",
       "      <td>0.026258</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.045043</td>\n",
       "      <td>0.029049</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>0.032066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id         IC_01         IC_07         IC_05         IC_16  \\\n",
       "count  11754.000000  11754.000000  11754.000000  11754.000000  11754.000000   \n",
       "mean   15877.500000      0.005423      0.009251      0.010635      0.001054   \n",
       "std     3393.231867      0.004552      0.004153      0.003609      0.003591   \n",
       "min    10001.000000     -0.015894     -0.015927     -0.002240     -0.013459   \n",
       "25%    12939.250000      0.002527      0.006495      0.008159     -0.001319   \n",
       "50%    15877.500000      0.005546      0.009192      0.010572      0.000956   \n",
       "75%    18815.750000      0.008476      0.011990      0.013009      0.003432   \n",
       "max    21754.000000      0.024189      0.029621      0.026218      0.022613   \n",
       "\n",
       "              IC_26         IC_06         IC_10         IC_09         IC_18  \\\n",
       "count  11754.000000  11754.000000  11754.000000  11754.000000  11754.000000   \n",
       "mean      -0.001271      0.013410      0.013749      0.001988      0.005053   \n",
       "std        0.002658      0.004032      0.003905      0.003200      0.005296   \n",
       "min       -0.015118     -0.002929      0.001156     -0.009622     -0.027575   \n",
       "25%       -0.002904      0.010764      0.011048     -0.000185      0.002079   \n",
       "50%       -0.001132      0.013513      0.013545      0.001917      0.005605   \n",
       "75%        0.000535      0.016087      0.016186      0.004113      0.008734   \n",
       "max        0.007863      0.028797      0.035586      0.015763      0.022121   \n",
       "\n",
       "       ...         IC_08         IC_03         IC_21         IC_28  \\\n",
       "count  ...  11754.000000  11754.000000  11754.000000  11754.000000   \n",
       "mean   ...      0.010036      0.020869      0.009754     -0.008081   \n",
       "std    ...      0.003914      0.003542      0.004609      0.003267   \n",
       "min    ...     -0.005282      0.008878     -0.010426     -0.020051   \n",
       "25%    ...      0.007356      0.018471      0.006692     -0.010231   \n",
       "50%    ...      0.009942      0.020620      0.009860     -0.008101   \n",
       "75%    ...      0.012616      0.023098      0.012876     -0.005915   \n",
       "max    ...      0.028522      0.036454      0.026258      0.005262   \n",
       "\n",
       "              IC_11         IC_20         IC_30         IC_22         IC_29  \\\n",
       "count  11754.000000  11754.000000  11754.000000  11754.000000  11754.000000   \n",
       "mean       0.023412      0.005084      0.003595     -0.014729      0.026623   \n",
       "std        0.004578      0.003697      0.002846      0.005972      0.004039   \n",
       "min        0.008485     -0.007969     -0.007720     -0.040384      0.013261   \n",
       "25%        0.020266      0.002550      0.001677     -0.018738      0.023791   \n",
       "50%        0.023231      0.004953      0.003539     -0.014498      0.026411   \n",
       "75%        0.026302      0.007421      0.005454     -0.010635      0.029244   \n",
       "max        0.045043      0.029049      0.016599      0.005710      0.044570   \n",
       "\n",
       "              IC_14  \n",
       "count  11754.000000  \n",
       "mean       0.016187  \n",
       "std        0.003731  \n",
       "min        0.001266  \n",
       "25%        0.013595  \n",
       "50%        0.016031  \n",
       "75%        0.018599  \n",
       "max        0.032066  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11754, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(l_data.tail())\n",
    "display(l_data.describe()),\n",
    "l_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630      0.000000      0.000000     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if IMPUTATION_STRAT == 'IGNORE_ON_TRAIN':\n",
    "    ## will later ignore the value when executing the loss function\n",
    "    y_data = y_data.fillna(0)\n",
    "else: #'MEAN'\n",
    "    y_data = y_data.fillna(mean())\n",
    "    \n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Combine Xs and Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IC_01</th>\n",
       "      <th>IC_07</th>\n",
       "      <th>IC_05</th>\n",
       "      <th>IC_16</th>\n",
       "      <th>IC_26</th>\n",
       "      <th>IC_06</th>\n",
       "      <th>IC_10</th>\n",
       "      <th>IC_09</th>\n",
       "      <th>IC_18</th>\n",
       "      <th>IC_04</th>\n",
       "      <th>...</th>\n",
       "      <th>IC_20</th>\n",
       "      <th>IC_30</th>\n",
       "      <th>IC_22</th>\n",
       "      <th>IC_29</th>\n",
       "      <th>IC_14</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>-0.002742</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.016720</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>-0.023235</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009087</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>-0.002076</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>-0.016609</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.001222</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.027787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>0.024476</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.021058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>-0.019814</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>0.013316</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.002255</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>-0.008462</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>-0.001115</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.027352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0.032932</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.016489</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.005044</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>-0.006267</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>0.031161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>-0.022357</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.016982</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>0.033895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>0.021665</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.001773</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>-0.020373</td>\n",
       "      <td>0.023804</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IC_01     IC_07     IC_05     IC_16     IC_26     IC_06     IC_10  \\\n",
       "0     0.006070  0.014466  0.004136  0.000658 -0.002742  0.005033  0.016720   \n",
       "1     0.009087  0.009291  0.007049 -0.002076 -0.002227  0.004605  0.012277   \n",
       "2     0.004675  0.000957  0.006154 -0.000429 -0.001222  0.011755  0.013010   \n",
       "3    -0.000398  0.006878  0.009051  0.000369  0.000336  0.010679  0.010352   \n",
       "4     0.005192  0.010585  0.012160 -0.000920 -0.002255  0.011416  0.013838   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5872 -0.001115  0.007108  0.008652  0.003596  0.000950  0.016314  0.017090   \n",
       "5873  0.007263  0.016489  0.012704  0.004357 -0.005044  0.013909  0.019284   \n",
       "5874  0.005996  0.003873  0.012353  0.000242 -0.002159  0.020201  0.020931   \n",
       "5875  0.000627  0.011407  0.010957  0.000534 -0.000347  0.013499  0.010541   \n",
       "5876  0.010670  0.010670  0.006662 -0.002215 -0.001773  0.006544  0.010900   \n",
       "\n",
       "         IC_09     IC_18     IC_04  ...     IC_20     IC_30     IC_22  \\\n",
       "0     0.003484  0.001797  0.029223  ...  0.010496  0.002892 -0.023235   \n",
       "1     0.002946  0.004086  0.027333  ...  0.005739  0.002880 -0.016609   \n",
       "2     0.000193  0.008075  0.027787  ... -0.000319  0.005866 -0.015182   \n",
       "3     0.003637  0.004180  0.021058  ...  0.000786  0.002692 -0.019814   \n",
       "4     0.001929  0.003051  0.031867  ...  0.003731  0.000733 -0.008462   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5872  0.003513  0.004217  0.027352  ...  0.006943  0.003312 -0.011562   \n",
       "5873 -0.006267 -0.000456  0.031161  ...  0.001316  0.003792 -0.022357   \n",
       "5874  0.003684 -0.002458  0.033895  ...  0.004942  0.007751 -0.020226   \n",
       "5875  0.001867  0.007447  0.020901  ...  0.002026  0.001876 -0.014612   \n",
       "5876  0.000563  0.002995  0.023936  ...  0.002420  0.003115 -0.020373   \n",
       "\n",
       "         IC_29     IC_14        age  domain1_var1  domain1_var2  domain2_var1  \\\n",
       "0     0.022177  0.017192  57.436077     30.571975     62.553736     53.325130   \n",
       "1     0.025543  0.014524  59.580851     50.969456     67.470628     60.651856   \n",
       "2     0.024476  0.014760  71.413018     53.152498     58.012103     52.418389   \n",
       "3     0.017105  0.013316  66.532630      0.000000      0.000000     52.108977   \n",
       "4     0.026733  0.014358  38.617381     49.197021     65.674285     40.151376   \n",
       "...        ...       ...        ...           ...           ...           ...   \n",
       "5872  0.032932  0.011053  14.257265     21.358872     61.165998     51.778483   \n",
       "5873  0.031624  0.016982  55.456978     68.169675     29.907995     55.349257   \n",
       "5874  0.028821  0.017492  48.948756     55.114811     60.878271     38.617246   \n",
       "5875  0.021665  0.019592  66.532630     59.844808     72.303110     55.458281   \n",
       "5876  0.023804  0.012477  68.820928     56.594193     34.605868     49.922535   \n",
       "\n",
       "      domain2_var2  \n",
       "0        51.427998  \n",
       "1        58.311361  \n",
       "2        62.536641  \n",
       "3        69.993075  \n",
       "4        34.096421  \n",
       "...            ...  \n",
       "5872     54.640179  \n",
       "5873     54.019517  \n",
       "5874     50.679885  \n",
       "5875     46.870235  \n",
       "5876     50.383078  \n",
       "\n",
       "[5877 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = l_data.merge(y_data, on='Id', how='inner').sort_values(by='Id').reset_index(drop = True)\n",
    "idx_train = train.pop('Id') \n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IC_01</th>\n",
       "      <th>IC_07</th>\n",
       "      <th>IC_05</th>\n",
       "      <th>IC_16</th>\n",
       "      <th>IC_26</th>\n",
       "      <th>IC_06</th>\n",
       "      <th>IC_10</th>\n",
       "      <th>IC_09</th>\n",
       "      <th>IC_18</th>\n",
       "      <th>IC_04</th>\n",
       "      <th>...</th>\n",
       "      <th>IC_08</th>\n",
       "      <th>IC_03</th>\n",
       "      <th>IC_21</th>\n",
       "      <th>IC_28</th>\n",
       "      <th>IC_11</th>\n",
       "      <th>IC_20</th>\n",
       "      <th>IC_30</th>\n",
       "      <th>IC_22</th>\n",
       "      <th>IC_29</th>\n",
       "      <th>IC_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>-0.005293</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>-0.008021</td>\n",
       "      <td>0.038530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>-0.010469</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>-0.028882</td>\n",
       "      <td>0.031427</td>\n",
       "      <td>0.018164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.038693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>-0.010414</td>\n",
       "      <td>0.023518</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>-0.030771</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.002884</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>0.015651</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.033243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>-0.005653</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>0.027287</td>\n",
       "      <td>0.014542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>-0.003944</td>\n",
       "      <td>0.027572</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-0.013350</td>\n",
       "      <td>0.033612</td>\n",
       "      <td>0.019472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007521</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>0.027038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.026314</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>-0.010203</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.024723</td>\n",
       "      <td>0.024084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.035930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.024635</td>\n",
       "      <td>0.013140</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>0.027616</td>\n",
       "      <td>0.018392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>-0.003072</td>\n",
       "      <td>0.010702</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>0.017368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>-0.005683</td>\n",
       "      <td>-0.011613</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.030379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>-0.003296</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>0.029249</td>\n",
       "      <td>0.015356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>-0.008028</td>\n",
       "      <td>0.035093</td>\n",
       "      <td>0.017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>-0.005623</td>\n",
       "      <td>-0.006399</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.042646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>-0.008130</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>0.029326</td>\n",
       "      <td>0.014235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IC_01     IC_07     IC_05     IC_16     IC_26     IC_06     IC_10  \\\n",
       "0     0.008151  0.014684  0.010444 -0.005293 -0.002913  0.015042  0.017745   \n",
       "1     0.000334  0.005311  0.010053  0.006920 -0.000065  0.015310  0.016543   \n",
       "2     0.007103  0.006144  0.009770 -0.002884 -0.001346  0.015651  0.011613   \n",
       "3     0.004362  0.010240  0.010167  0.004492 -0.001623  0.017381  0.014680   \n",
       "4    -0.007521 -0.003918  0.008434 -0.001145  0.002017  0.015065  0.019616   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5872  0.005406  0.006275  0.012252  0.003518  0.001400  0.015054  0.015373   \n",
       "5873  0.004240  0.009213  0.010981  0.000443 -0.003072  0.010702  0.014673   \n",
       "5874  0.004783  0.017910  0.012128 -0.005683 -0.011613  0.017000  0.007230   \n",
       "5875  0.003835  0.015067  0.015428 -0.002030  0.001205  0.012396  0.011026   \n",
       "5876  0.007431  0.021419  0.014143 -0.005623 -0.006399  0.008602  0.006831   \n",
       "\n",
       "         IC_09     IC_18     IC_04  ...     IC_08     IC_03     IC_21  \\\n",
       "0     0.003930 -0.008021  0.038530  ...  0.019565  0.030616  0.018184   \n",
       "1     0.004794  0.003982  0.038693  ...  0.006948  0.019818  0.003582   \n",
       "2    -0.003291  0.013423  0.033243  ...  0.001252  0.020002  0.013935   \n",
       "3     0.007453  0.008786  0.029094  ...  0.014015  0.022257  0.008814   \n",
       "4     0.004140 -0.003744  0.027038  ...  0.010726  0.026314  0.007632   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5872  0.001532  0.003546  0.035930  ...  0.009398  0.024635  0.013140   \n",
       "5873  0.005523  0.005780  0.022570  ...  0.011172  0.017172  0.003079   \n",
       "5874  0.001315  0.008788  0.030379  ...  0.010015  0.017097  0.016017   \n",
       "5875 -0.001491  0.005310  0.023853  ...  0.012303  0.018314  0.012326   \n",
       "5876 -0.001018  0.014972  0.042646  ...  0.019220  0.026282  0.020715   \n",
       "\n",
       "         IC_28     IC_11     IC_20     IC_30     IC_22     IC_29     IC_14  \n",
       "0    -0.010469  0.029799  0.015435  0.005211 -0.028882  0.031427  0.018164  \n",
       "1    -0.010414  0.023518  0.005929  0.005046 -0.030771  0.028500  0.022485  \n",
       "2    -0.005653  0.013281  0.003379  0.004841 -0.009467  0.027287  0.014542  \n",
       "3    -0.003944  0.027572  0.008287  0.000210 -0.013350  0.033612  0.019472  \n",
       "4    -0.010203  0.022945  0.007642  0.003368 -0.024025  0.024723  0.024084  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5872 -0.007455  0.023625  0.005393  0.007665 -0.011987  0.027616  0.018392  \n",
       "5873 -0.007329  0.021157  0.007605  0.009629 -0.019956  0.024192  0.017368  \n",
       "5874 -0.003296  0.018724  0.008006 -0.000521 -0.001333  0.029249  0.015356  \n",
       "5875 -0.012152  0.024617  0.002096  0.001911 -0.008028  0.035093  0.017439  \n",
       "5876 -0.008130  0.025149  0.007695  0.003226 -0.003505  0.029326  0.014235  \n",
       "\n",
       "[5877 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = l_data.merge(y_data, on='Id', how='outer', indicator = True)\n",
    "test = test[test['_merge'] == 'left_only'].drop(['age',\n",
    "                                                 'domain1_var1', \n",
    "                                                 'domain1_var2',\n",
    "                                                 'domain2_var1',\n",
    "                                                 'domain2_var2',\n",
    "                                                 '_merge'], axis = 1).sort_values(by='Id').reset_index(drop = True)\n",
    "idx_test = test.pop('Id') \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# variation of https://github.com/fastai/fastai/blob/master/fastai/metrics.py#L85\n",
    "\n",
    "def norm_absolute_error(preds, targs):\n",
    "    \"Normalized absolute error between `pred` and `targ`.\"\n",
    "    sg=targs.sign()\n",
    "    y=targs*sg\n",
    "        \n",
    "    pred, targ = flatten_check(preds*sg, y)\n",
    "    return torch.abs(targ - pred).sum() / targ.sum()\n",
    "\n",
    "def weighted_nae(preds, targs):\n",
    "    return 0.3 * norm_absolute_error(preds[:,0],targs[:,0]) + \\\n",
    "           0.175 * norm_absolute_error(preds[:,1],targs[:,1]) + \\\n",
    "           0.175 * norm_absolute_error(preds[:,2],targs[:,2]) + \\\n",
    "           0.175 * norm_absolute_error(preds[:,3],targs[:,3]) + \\\n",
    "           0.175 * norm_absolute_error(preds[:,4],targs[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The customized metric callback is a variation of https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964. \n",
    "It is used to keep track of the five single targets and the combined metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# variation of https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964\n",
    "\n",
    "class Metric_idx(Callback):\n",
    "    def __init__(self, idx):\n",
    "        super().__init__()\n",
    "        self.idx = idx\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.targs, self.preds = Tensor([]), Tensor([])\n",
    "    \n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "        last_output = last_output[self.idx]\n",
    "        last_target = last_target[self.idx]\n",
    "        \n",
    "        self.preds = torch.cat((self.preds, last_output.float().cpu()))\n",
    "        self.targs = torch.cat((self.targs, last_target.float().cpu()))\n",
    "        \n",
    "    def _norm_absolute_error(self):\n",
    "        return norm_absolute_error(self.preds, self.targs)\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs): \n",
    "        return add_metrics(last_metrics, self._norm_absolute_error())\n",
    "\n",
    "    \n",
    "Metric_age = partial(Metric_idx,0)\n",
    "Metric_domain1_var1 = partial(Metric_idx,1)\n",
    "Metric_domain1_var2 = partial(Metric_idx,2)\n",
    "Metric_domain2_var1 = partial(Metric_idx,3)\n",
    "Metric_domain2_var2 = partial(Metric_idx,4)\n",
    "\n",
    "class Metric_total(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.age = Metric_idx(0)\n",
    "        self.domain1_var1 = Metric_idx(1)\n",
    "        self.domain1_var2 = Metric_idx(2)\n",
    "        self.domain2_var1 = Metric_idx(3)\n",
    "        self.domain2_var2 = Metric_idx(4)\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.age.on_epoch_begin(**kwargs)\n",
    "        self.domain1_var1.on_epoch_begin(**kwargs)\n",
    "        self.domain1_var2.on_epoch_begin(**kwargs)\n",
    "        self.domain2_var1.on_epoch_begin(**kwargs)\n",
    "        self.domain2_var2.on_epoch_begin(**kwargs)\n",
    "        \n",
    "    \n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "        self.age.on_batch_end(last_output, last_target, **kwargs)\n",
    "        self.domain1_var1.on_batch_end(last_output, last_target, **kwargs)\n",
    "        self.domain1_var2.on_batch_end(last_output, last_target, **kwargs)\n",
    "        self.domain2_var1.on_batch_end(last_output, last_target, **kwargs)\n",
    "        self.domain2_var2.on_batch_end(last_output, last_target, **kwargs)\n",
    " \n",
    "        \n",
    "    def on_epoch_end(self, last_metrics, **kwargs): \n",
    "        return add_metrics(last_metrics, \n",
    "                           0.3 * self.age._norm_absolute_error() +\n",
    "                           0.175*self.domain1_var1._norm_absolute_error()  +\n",
    "                           0.175*self.domain1_var2._norm_absolute_error()  +\n",
    "                           0.175*self.domain2_var1._norm_absolute_error()  +\n",
    "                           0.175*self.domain2_var2._norm_absolute_error()\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Loss function\n",
    "The customized metric callback is a variation of https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964. It weights and combines the five single losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# variation of https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964\n",
    "\n",
    "class Loss_combine(nn.Module):\n",
    "    def __init__(self, loss_weights = [0.4,0.15,0.15,0.15,0.15], loss_base = 'MSE'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_base = loss_base\n",
    "        \n",
    "        self.loss_weights = loss_weights\n",
    "        self.fw = Tensor(LOSS_WEIGHTS).cuda()\n",
    "          \n",
    "            \n",
    "    def forward(self, input, target,reduction='mean'): #mean\n",
    "        \n",
    "        x0,x1,x2,x3,x4 = input.T\n",
    "        \n",
    "        if IMPUTATION_STRAT == 'IGNORE_ON_TRAIN':\n",
    "            sg = target.float().sign()\n",
    "            x0,x1,x2,x3,x4 = x0.float()*sg[:,0],x1.float()*sg[:,1],x2.float()*sg[:,2],x3.float()*sg[:,3],x4.float()*sg[:,4]\n",
    "        else: # 'MEAN'\n",
    "            sg = 1\n",
    "            x0,x1,x2,x3,x4 = x0.float(),x1.float(),x2.float(),x3.float(),x4.float()\n",
    "            \n",
    "        y = target.float()*sg\n",
    "        \n",
    "        if self.loss_base == 'MSE':\n",
    "            loss_func = F.mse_loss \n",
    "            reduction = 'sum'\n",
    "            return self.fw[0]*loss_func(x0,y[:,0],reduction=reduction)/sum(y[:,0]**2) + \\\n",
    "               self.fw[1]*loss_func(x1,y[:,1],reduction=reduction)/sum(y[:,1]**2) + \\\n",
    "               self.fw[2]*loss_func(x2,y[:,2],reduction=reduction)/sum(y[:,2]**2) + \\\n",
    "               self.fw[3]*loss_func(x3,y[:,3],reduction=reduction)/sum(y[:,3]**2) + \\\n",
    "               self.fw[4]*loss_func(x4,y[:,4],reduction=reduction)/sum(y[:,4]**2)\n",
    "        else: # 'L1'\n",
    "            loss_func = F.l1_loss \n",
    "            reduction = 'mean'\n",
    "            return self.fw[0]*loss_func(x0,y[:,0],reduction=reduction) + \\\n",
    "               self.fw[1]*loss_func(x1,y[:,1],reduction=reduction) + \\\n",
    "               self.fw[2]*loss_func(x2,y[:,2],reduction=reduction) + \\\n",
    "               self.fw[3]*loss_func(x3,y[:,3],reduction=reduction) + \\\n",
    "               self.fw[4]*loss_func(x4,y[:,4],reduction=reduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "Augmentation is broadly used for sample generation and regularization in image classification. This is a try to use the techniques on tabular data.\n",
    "\n",
    "The Mixup implementation is a variation of https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py following this [example](https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964#MixUp) and adaptied for tabular data following this [thread](https://forums.fast.ai/t/tabulardata-mixup/52011/6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Vartiation https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L8\n",
    "# and https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964#MixUp\n",
    "# and https://forums.fast.ai/t/tabulardata-mixup/52011/6\n",
    "\n",
    "class MixUpLoss(Module):\n",
    "    \"Adapt the loss function `crit` to go with mixup.\"\n",
    "    \n",
    "    def __init__(self, crit, reduction='mean'): #mean\n",
    "        super().__init__()\n",
    "        if hasattr(crit, 'reduction'): \n",
    "            self.crit = crit\n",
    "            self.old_red = crit.reduction\n",
    "            setattr(self.crit, 'reduction', 'none')\n",
    "        else: \n",
    "            self.crit = partial(crit, reduction='none')\n",
    "            self.old_crit = crit\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        if len(target.shape) == 2 and target.shape[1] == 11:\n",
    "            loss1, loss2 = self.crit(output,target[:,0:5].long()), self.crit(output,target[:,5:10].long())\n",
    "            d = loss1 * target[:,-1] + loss2 * (1-target[:,-1])\n",
    "        else:  d = self.crit(output, target)\n",
    "        \n",
    "        if self.reduction == 'mean':    return d.mean()\n",
    "        elif self.reduction == 'sum':   return d.sum()\n",
    "        return d\n",
    "    \n",
    "    def get_old(self):\n",
    "        if hasattr(self, 'old_crit'):  return self.old_crit\n",
    "        elif hasattr(self, 'old_red'): \n",
    "            setattr(self.crit, 'reduction', self.old_red)\n",
    "            return self.crit\n",
    "\n",
    "class MixUpCallback(LearnerCallback):\n",
    "    \"Callback that creates the mixed-up input and target.\"\n",
    "    def __init__(self, learn:Learner, alpha:float=0.4, stack_x:bool=False, stack_y:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.alpha,self.stack_x,self.stack_y = alpha,stack_x,stack_y\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = MixUpLoss(self.learn.loss_func)\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        \"Applies mixup to `last_input` and `last_target` if `train`.\"\n",
    "        if not train: return\n",
    "        \n",
    "        # last_input[0] ==> embedded categorical data\n",
    "        # last_input[1] ==> continous data\n",
    "        rnd = 1\n",
    "        #if .5<np.random.uniform():\n",
    "        #    rnd=np.random.uniform()/20\n",
    "        \n",
    "        l_org = last_input[1] * rnd\n",
    "        last_input = last_input[1] *rnd #0\n",
    "        \n",
    "        lambd = np.random.beta(self.alpha, self.alpha, last_target.size(0))\n",
    "        lambd = np.concatenate([lambd[:,None], 1-lambd[:,None]], 1).max(1)\n",
    "        \n",
    "        lambd = last_input.new(lambd)\n",
    "        shuffle = torch.randperm(last_target.size(0)).to(last_input.device)\n",
    "        x1, y1 = last_input[shuffle], last_target[shuffle]\n",
    "        if self.stack_x:\n",
    "            new_input = [last_input, last_input[shuffle], lambd]\n",
    "        else: \n",
    "            out_shape = [lambd.size(0)] + [1 for _ in range(len(x1.shape) - 1)]\n",
    "            new_input = (last_input * lambd.view(out_shape) + x1 * (1-lambd).view(out_shape))\n",
    "        if self.stack_y:\n",
    "            new_target = torch.cat([last_target.float(), y1.float(), lambd[:,None].float()], 1)\n",
    "        else:\n",
    "            if len(last_target.shape) == 2:\n",
    "                lambd = lambd.unsqueeze(1).float()\n",
    "            new_target = last_target.float() * lambd + y1.float() * (1-lambd)\n",
    "        \n",
    "        return {'last_input': [l_org, new_input], 'last_target': new_target}  \n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = self.learn.loss_func.get_old()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "valid_idx = range(200, 400)\n",
    "dep_var = ['age','domain1_var1','domain1_var2', 'domain2_var1', 'domain2_var2']\n",
    "    \n",
    "def prep_data(bs, valid_idx):\n",
    "    procs = [FillMissing, Categorify, Normalize]\n",
    "    cont_names = list(set(train.columns) - set(['age','domain1_var1','domain1_var2', 'domain2_var1', 'domain2_var2'])-set(dep_var))\n",
    "    cat_names = []\n",
    "\n",
    "    tlist = (TabularList.from_df(train, \n",
    "                                path=kaggle_path, \n",
    "                                cat_names=cat_names, \n",
    "                                cont_names=cont_names, \n",
    "                                procs=procs))\n",
    "\n",
    "    if valid_idx == None:\n",
    "        tlist = tlist.split_none()\n",
    "    else:\n",
    "        tlist = tlist.split_by_idx(valid_idx)\n",
    "\n",
    "    data = (tlist.label_from_df(cols=dep_var)\n",
    "                 .add_test(TabularList.from_df(test, \n",
    "                                               cat_names=cat_names,\n",
    "                                               cont_names=cont_names, \n",
    "                                               procs = procs))\n",
    "                 .databunch(path = kaggle_path, bs = bs))\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def prep_learn(data):\n",
    "    \n",
    "    learn = tabular_learner(data, \n",
    "                        layers = [256,128,256,128,64], #[1024,1024,128,1024,128,1024,1024],#\n",
    "                        ps = 0.3,\n",
    "                        loss_func = Loss_combine(loss_weights = LOSS_WEIGHTS,  loss_base= LOSS_BASE),\n",
    "                        metrics=[Metric_age(),\n",
    "                                 Metric_domain1_var1(),\n",
    "                                 Metric_domain1_var2(),\n",
    "                                 Metric_domain2_var1(),\n",
    "                                 Metric_domain2_var2(),\n",
    "                                 Metric_total()],\n",
    "                       y_range=(Tensor([12,12,0,0,0]).cuda(),Tensor([90,90,100,100,100]).cuda())\n",
    "                       )#.to_fp16()\n",
    "\n",
    "    learn.clip_grad = 1.0\n",
    "    \n",
    "    return learn\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Training experiment without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep_data(bs, valid_idx)\n",
    "learn = prep_learn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      66.67% [2/3 00:03<00:01]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_total</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.125929</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.45% [9/44 00:00<00:01 0.1985]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 1.91E-02\n",
      "Min loss divided by 10: 6.31E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_total</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.074394</td>\n",
       "      <td>0.048378</td>\n",
       "      <td>0.145570</td>\n",
       "      <td>0.213363</td>\n",
       "      <td>0.129116</td>\n",
       "      <td>0.179113</td>\n",
       "      <td>0.142790</td>\n",
       "      <td>0.159938</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.052765</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>0.155490</td>\n",
       "      <td>0.214983</td>\n",
       "      <td>0.108319</td>\n",
       "      <td>0.162541</td>\n",
       "      <td>0.146863</td>\n",
       "      <td>0.157370</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046849</td>\n",
       "      <td>0.045779</td>\n",
       "      <td>0.144407</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.145344</td>\n",
       "      <td>0.180382</td>\n",
       "      <td>0.114338</td>\n",
       "      <td>0.156295</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.043979</td>\n",
       "      <td>0.043865</td>\n",
       "      <td>0.143256</td>\n",
       "      <td>0.198130</td>\n",
       "      <td>0.108025</td>\n",
       "      <td>0.169836</td>\n",
       "      <td>0.112460</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042460</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>0.149572</td>\n",
       "      <td>0.191454</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.178340</td>\n",
       "      <td>0.128675</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.041149</td>\n",
       "      <td>0.143344</td>\n",
       "      <td>0.202726</td>\n",
       "      <td>0.134747</td>\n",
       "      <td>0.163548</td>\n",
       "      <td>0.142162</td>\n",
       "      <td>0.155560</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.040672</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.192464</td>\n",
       "      <td>0.120680</td>\n",
       "      <td>0.171071</td>\n",
       "      <td>0.132269</td>\n",
       "      <td>0.151273</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.039947</td>\n",
       "      <td>0.041226</td>\n",
       "      <td>0.144693</td>\n",
       "      <td>0.206070</td>\n",
       "      <td>0.123777</td>\n",
       "      <td>0.168625</td>\n",
       "      <td>0.135892</td>\n",
       "      <td>0.154422</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.039220</td>\n",
       "      <td>0.040978</td>\n",
       "      <td>0.139290</td>\n",
       "      <td>0.201899</td>\n",
       "      <td>0.131046</td>\n",
       "      <td>0.166693</td>\n",
       "      <td>0.132535</td>\n",
       "      <td>0.152417</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.038982</td>\n",
       "      <td>0.041033</td>\n",
       "      <td>0.140769</td>\n",
       "      <td>0.202486</td>\n",
       "      <td>0.128595</td>\n",
       "      <td>0.166356</td>\n",
       "      <td>0.133225</td>\n",
       "      <td>0.152596</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 2e-2\n",
    "reduceLR = callbacks.ReduceLROnPlateauCallback(learn=learn, monitor = 'valid_loss', mode = 'auto', patience = 2, factor = 0.2, min_delta = 0)\n",
    "learn.fit_one_cycle(10, lr, callbacks=[reduceLR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without augmentation:\n",
      "Weighted normalized absolute error (Valid): 0.1666399985551834\n",
      "Weighted normalized absolute error (Train): 0.15863674879074097\n"
     ]
    }
   ],
   "source": [
    "yv, yv_truth= learn.get_preds(ds_type=DatasetType.Valid)\n",
    "yt, yt_truth= learn.get_preds(ds_type=DatasetType.Train)\n",
    "\n",
    "print(f'Without augmentation:')\n",
    "print(f'Weighted normalized absolute error (Valid): {weighted_nae(yv,yv_truth)}')\n",
    "print(f'Weighted normalized absolute error (Train): {weighted_nae(yt,yt_truth)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Training experiment with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_total</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.074599</td>\n",
       "      <td>0.047370</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217852</td>\n",
       "      <td>0.146760</td>\n",
       "      <td>0.160210</td>\n",
       "      <td>0.147791</td>\n",
       "      <td>0.161885</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.056145</td>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.141088</td>\n",
       "      <td>0.232976</td>\n",
       "      <td>0.134788</td>\n",
       "      <td>0.169377</td>\n",
       "      <td>0.134513</td>\n",
       "      <td>0.159866</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051165</td>\n",
       "      <td>0.046093</td>\n",
       "      <td>0.143940</td>\n",
       "      <td>0.216906</td>\n",
       "      <td>0.120940</td>\n",
       "      <td>0.150752</td>\n",
       "      <td>0.187125</td>\n",
       "      <td>0.161433</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049076</td>\n",
       "      <td>0.043026</td>\n",
       "      <td>0.142077</td>\n",
       "      <td>0.204314</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>0.176401</td>\n",
       "      <td>0.138936</td>\n",
       "      <td>0.158884</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047578</td>\n",
       "      <td>0.041334</td>\n",
       "      <td>0.141251</td>\n",
       "      <td>0.202758</td>\n",
       "      <td>0.140460</td>\n",
       "      <td>0.171068</td>\n",
       "      <td>0.151608</td>\n",
       "      <td>0.158907</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046257</td>\n",
       "      <td>0.041406</td>\n",
       "      <td>0.147281</td>\n",
       "      <td>0.197755</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>0.170109</td>\n",
       "      <td>0.153160</td>\n",
       "      <td>0.159747</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>0.132730</td>\n",
       "      <td>0.207298</td>\n",
       "      <td>0.131345</td>\n",
       "      <td>0.170272</td>\n",
       "      <td>0.133882</td>\n",
       "      <td>0.152309</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.045191</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.139081</td>\n",
       "      <td>0.204365</td>\n",
       "      <td>0.137816</td>\n",
       "      <td>0.169818</td>\n",
       "      <td>0.145324</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.137706</td>\n",
       "      <td>0.200681</td>\n",
       "      <td>0.131503</td>\n",
       "      <td>0.165386</td>\n",
       "      <td>0.136190</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044511</td>\n",
       "      <td>0.040919</td>\n",
       "      <td>0.136772</td>\n",
       "      <td>0.200979</td>\n",
       "      <td>0.136945</td>\n",
       "      <td>0.168025</td>\n",
       "      <td>0.141059</td>\n",
       "      <td>0.154258</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = prep_data(bs, valid_idx)\n",
    "learn = prep_learn(data)\n",
    "\n",
    "lr = 2e-2\n",
    "reduceLR = callbacks.ReduceLROnPlateauCallback(learn=learn, monitor = 'valid_loss', mode = 'auto', patience = 2, factor = 0.2, min_delta = 0)\n",
    "learn.fit_one_cycle(10, lr, callbacks=[MixUpCallback(learn, alpha=0.4),reduceLR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With augmentation:\n",
      "Weighted normalized absolute error (Valid): 0.1668575406074524\n",
      "Weighted normalized absolute error (Train): 0.16082099080085754\n"
     ]
    }
   ],
   "source": [
    "yv, yv_truth= learn.get_preds(ds_type=DatasetType.Valid)\n",
    "yt, yt_truth= learn.get_preds(ds_type=DatasetType.Train)\n",
    "\n",
    "print(f'With augmentation:')\n",
    "print(f'Weighted normalized absolute error (Valid): {weighted_nae(yv,yv_truth)}')\n",
    "print(f'Weighted normalized absolute error (Train): {weighted_nae(yt,yt_truth)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Training conclution\n",
    "\n",
    "The choosen augmentation technique in this configuration doesn't improve the validation score. \n",
    "\n",
    "Let's see if it generalizes better on the LB."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def make_submission(learn, postfix = ''):\n",
    "    preds = learn.get_preds(ds_type=DatasetType.Test)[0]\n",
    "    \n",
    "    rec = pd.DataFrame(idx_test)\n",
    "    rec['Id'] = rec['Id'].astype(str)+'_'\n",
    "    rec['Predicted'] = preds[:,1]\n",
    "    \n",
    "    submission=None\n",
    "\n",
    "    for t, tcol in enumerate(dep_var):\n",
    "        rec = pd.DataFrame(idx_test)\n",
    "        rec['Id'] = rec['Id'].astype(str)+'_'+tcol\n",
    "        rec['Predicted'] = preds[:,t]\n",
    "        if isinstance(submission, pd.DataFrame):\n",
    "            submission = submission.append(rec)\n",
    "        else:\n",
    "            submission = rec\n",
    "\n",
    "    submission = submission.sort_values('Id').reset_index(drop=True)\n",
    "    \n",
    "    display(submission.head(10))\n",
    "    submission.to_csv('submission'+postfix+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Predict without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_total</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.075022</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044254</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.041207</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.039712</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.039194</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.038884</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = prep_data(bs, valid_idx = None)\n",
    "learn = prep_learn(data)\n",
    "\n",
    "lr = 2e-2\n",
    "learn.fit_one_cycle(10, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003_age</td>\n",
       "      <td>45.986549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003_domain1_var1</td>\n",
       "      <td>49.061516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003_domain1_var2</td>\n",
       "      <td>58.304142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003_domain2_var1</td>\n",
       "      <td>46.252407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_domain2_var2</td>\n",
       "      <td>54.012333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10006_age</td>\n",
       "      <td>62.886322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006_domain1_var1</td>\n",
       "      <td>54.765713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10006_domain1_var2</td>\n",
       "      <td>59.264137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10006_domain2_var1</td>\n",
       "      <td>50.623482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10006_domain2_var2</td>\n",
       "      <td>50.019474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Predicted\n",
       "0           10003_age  45.986549\n",
       "1  10003_domain1_var1  49.061516\n",
       "2  10003_domain1_var2  58.304142\n",
       "3  10003_domain2_var1  46.252407\n",
       "4  10003_domain2_var2  54.012333\n",
       "5           10006_age  62.886322\n",
       "6  10006_domain1_var1  54.765713\n",
       "7  10006_domain1_var2  59.264137\n",
       "8  10006_domain2_var1  50.623482\n",
       "9  10006_domain2_var2  50.019474"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_submission(learn, postfix = '_wo_aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Predict with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_idx</th>\n",
       "      <th>metric_total</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051413</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048766</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047174</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045697</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.045231</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = prep_data(bs, valid_idx = None)\n",
    "learn = prep_learn(data)\n",
    "\n",
    "lr = 2e-2\n",
    "learn.fit_one_cycle(10, lr, callbacks=[MixUpCallback(learn, alpha=0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003_age</td>\n",
       "      <td>46.059483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003_domain1_var1</td>\n",
       "      <td>49.057041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003_domain1_var2</td>\n",
       "      <td>58.605530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003_domain2_var1</td>\n",
       "      <td>46.528221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_domain2_var2</td>\n",
       "      <td>53.103851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10006_age</td>\n",
       "      <td>56.708973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006_domain1_var1</td>\n",
       "      <td>53.018108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10006_domain1_var2</td>\n",
       "      <td>58.169304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10006_domain2_var1</td>\n",
       "      <td>48.636211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10006_domain2_var2</td>\n",
       "      <td>50.629307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Predicted\n",
       "0           10003_age  46.059483\n",
       "1  10003_domain1_var1  49.057041\n",
       "2  10003_domain1_var2  58.605530\n",
       "3  10003_domain2_var1  46.528221\n",
       "4  10003_domain2_var2  53.103851\n",
       "5           10006_age  56.708973\n",
       "6  10006_domain1_var1  53.018108\n",
       "7  10006_domain1_var2  58.169304\n",
       "8  10006_domain2_var1  48.636211\n",
       "9  10006_domain2_var2  50.629307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_submission(learn, postfix = '_with_aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "LB without augmentation: 0.164\n",
    "\n",
    "LB with augmentation: 0.165\n",
    "\n",
    "==> No advantage from augmentation is this particular setting. Got to try something else ... ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
